{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3974e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install findspark\n",
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2977e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ed94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b63a4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|   James |        MM|   Smith|36636|     M|  3300|\n",
      "|   Maria |      Rose|   Hills|40288|     F|  5000|\n",
      "|  Robert |       Fox|Williams|42114|     M|  4400|\n",
      "|    Loris|      Anne|   Jones|39192|     M|  6000|\n",
      "|      Jen|      Mary|   Brown|     |     F|  3333|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe\n",
    "data = [(\"James \",\"MM\",\"Smith\",\"36636\",\"M\",3300),\n",
    "              (\"Maria \",\"Rose\",\"Hills\",\"40288\",\"F\",5000),\n",
    "              (\"Robert \",\"Fox\",\"Williams\",\"42114\",\"M\",4400),\n",
    "              (\"Loris\",\"Anne\",\"Jones\",\"39192\",\"M\",6000),\n",
    "              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",3333)]\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5391d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parquet file\n",
    "df.write.parquet(\"data/people.paquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56d1170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['James ', 'Maria ', 'Robert ', 'Loris', 'Jen']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('firstname').rdd.flatMap(lambda x:x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86adc6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|  Robert |       Fox|Williams|42114|     M|  4400|\n",
      "|   Maria |      Rose|   Hills|40288|     F|  5000|\n",
      "|    Loris|      Anne|   Jones|39192|     M|  6000|\n",
      "|   James |        MM|   Smith|36636|     M|  3300|\n",
      "|      Jen|      Mary|   Brown|     |     F|  3333|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read a parquet file\n",
    "read_parq = spark.read.parquet(\"data/people.paquet\")\n",
    "read_parq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e8cf1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|  Robert |       Fox|Williams|42114|     M|  4400|\n",
      "|   Maria |      Rose|   Hills|40288|     F|  5000|\n",
      "|    Loris|      Anne|   Jones|39192|     M|  6000|\n",
      "|   James |        MM|   Smith|36636|     M|  3300|\n",
      "|      Jen|      Mary|   Brown|     |     F|  3333|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a tempview and show the result\n",
    "read_parq.createOrReplaceTempView(\"ParquetTable\")\n",
    "\n",
    "view_parq = spark.sql(\"select * from ParquetTable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab611c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partioned the parquet file by gender\n",
    "df.write.partitionBy(\"gender\").mode(\"overwrite\").parquet(\"data/people_by_gender.paquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1459bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|salary|gender|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|  Robert |       Fox|Williams|42114|  4400|     M|\n",
      "|   Maria |      Rose|   Hills|40288|  5000|     F|\n",
      "|    Loris|      Anne|   Jones|39192|  6000|     M|\n",
      "|   James |        MM|   Smith|36636|  3300|     M|\n",
      "|      Jen|      Mary|   Brown|     |  3333|     F|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read a parquet file\n",
    "read_partt = spark.read.parquet(\"data/people_by_gender.paquet\")\n",
    "read_partt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f3f92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|salary|gender|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|  Robert |       Fox|Williams|42114|  4400|     M|\n",
      "|   Maria |      Rose|   Hills|40288|  5000|     F|\n",
      "|    Loris|      Anne|   Jones|39192|  6000|     M|\n",
      "|   James |        MM|   Smith|36636|  3300|     M|\n",
      "|      Jen|      Mary|   Brown|     |  3333|     F|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a tempview and show the result\n",
    "read_partt.createOrReplaceTempView(\"ParquetTable_Gender\")\n",
    "\n",
    "view_partt = spark.sql(\"select * from ParquetTable_Gender\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9be81a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+\n",
      "|firstname|middlename|lastname|  dob|salary|\n",
      "+---------+----------+--------+-----+------+\n",
      "|  Robert |       Fox|Williams|42114|  4400|\n",
      "|    Loris|      Anne|   Jones|39192|  6000|\n",
      "|   James |        MM|   Smith|36636|  3300|\n",
      "+---------+----------+--------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read a parquet file partioned by gender\n",
    "read_by_gender_M = spark.read.parquet(\"data/people_by_gender.paquet/gender=M\")\n",
    "read_by_gender_M.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af1b129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+\n",
      "|firstname|middlename|lastname|  dob|salary|\n",
      "+---------+----------+--------+-----+------+\n",
      "|  Robert |       Fox|Williams|42114|  4400|\n",
      "|    Loris|      Anne|   Jones|39192|  6000|\n",
      "|   James |        MM|   Smith|36636|  3300|\n",
      "+---------+----------+--------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a tempview and show it\n",
    "read_by_gender_M.createOrReplaceTempView(\"ParquetTable_M\")\n",
    "\n",
    "view_by_gender_M = spark.sql(\"select * from ParquetTable_M\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57b33b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+\n",
      "|firstname|middlename|lastname|  dob|salary|\n",
      "+---------+----------+--------+-----+------+\n",
      "|   Maria |      Rose|   Hills|40288|  5000|\n",
      "|      Jen|      Mary|   Brown|     |  3333|\n",
      "+---------+----------+--------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a tempview using a parquet file and show the result\n",
    "spark.sql(\"CREATE TEMPORARY VIEW Person_Gender_F USING parquet OPTIONS (path \\\"data/people_by_gender.paquet/gender=F\\\")\")\n",
    "\n",
    "spark.sql(\"select * from Person_Gender_F\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e46ef1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   Name|  Date|\n",
      "+-------+------+\n",
      "|  James|202108|\n",
      "|Michael|202106|\n",
      "| Robert|202108|\n",
      "|  Maria|202106|\n",
      "|    Jen|202108|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read a csv file and show it\n",
    "df_csv = spark.read.options(header = \"True\", inferSchema = \"True\").csv(\"data/customers.csv\")\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df2 = df2.withColumn(\"date\", func.to_date(func.col(\"DateTime\")))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6e4071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parquet file\n",
    "df_csv.write.parquet(\"data/dt.paquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42083bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   Name|  Date|\n",
      "+-------+------+\n",
      "|  James|202108|\n",
      "|Michael|202106|\n",
      "| Robert|202108|\n",
      "|  Maria|202106|\n",
      "|    Jen|202108|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a parquet file\n",
    "rd_p = spark.read.parquet(\"data/dt.paquet\")\n",
    "rd_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77984c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   Name|  Date|\n",
      "+-------+------+\n",
      "|  James|202108|\n",
      "|Michael|202106|\n",
      "| Robert|202108|\n",
      "|  Maria|202106|\n",
      "|    Jen|202108|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a tempview and show the result\n",
    "rd_p.createOrReplaceTempView(\"ParquetTable_DT\")\n",
    "\n",
    "view_dt = spark.sql(\"select * from ParquetTable_DT\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a17c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partioned the parquet file by date\n",
    "df_csv.write.partitionBy(\"date\").mode(\"overwrite\").parquet(\"data/dt.paquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9b2e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "|Michael|\n",
      "|  Maria|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read a parquet file partioned by date\n",
    "rd_pd = spark.read.parquet(\"data/dt.paquet/date=202106\")\n",
    "rd_pd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "333ac503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "|Michael|\n",
      "|  Maria|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a tempview using a parquet file and show the result\n",
    "spark.sql(\"CREATE TEMPORARY VIEW ParquetTable_DTD USING parquet OPTIONS (path \\\"data/dt.paquet/date=202106\\\")\")\n",
    "\n",
    "spark.sql(\"select * from ParquetTable_DTD\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
